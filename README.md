# Amazon Food Review Sentiment Analysis

## ğŸ“Œ Project Overview

This project performs **sentiment analysis** on 568K+ Amazon Fine Food reviews using both classical NLP and deep learning approaches. It demonstrates end-to-end machine learning workflow: from data preprocessing, baseline modeling, transformer fine-tuning, to deployment on Hugging Face Spaces.

**Live Demo:** [Try it on Hugging Face Spaces](https://huggingface.co/spaces/YeswanthArasavalli/Amazon_Food_Review)

---

## ğŸ¯ Key Features

- **Data Processing:** Full preprocessing pipeline with text cleaning and tokenization
- **Baseline Model:** TF-IDF with Logistic Regression (~89% accuracy)
- **Deep Learning:** Fine-tuned DistilBERT Transformer (~94% accuracy)
- **Evaluation:** Comprehensive metrics including Confusion Matrix, ROC-AUC Curve, and error analysis
- **Deployment:** Interactive Gradio UI hosted on Hugging Face Spaces
- **Interpretability:** Misclassified examples analysis for model robustness

---

## ğŸ“Š Dataset

| Property | Details |
|----------|----------|
| **Source** | Amazon Fine Food Reviews (Kaggle) |
| **Records** | 568,454 reviews |
| **Sentiment Classes** | 3 (Negative, Neutral, Positive) |
| **Class Distribution** | 1-2: Negative, 3: Neutral, 4-5: Positive |

### Original Features
- Product metadata
- Timestamps
- Review text
- User ratings
- Helpfulness scores

---

## ğŸ§  Methodology

### 1. Baseline Model

| Metric | Value |
|--------|-------|
| **Technique** | TF-IDF (50k features) + Logistic Regression |
| **Accuracy** | ~89% |
| **F1-Score** | ~0.88 |

**Purpose:** Established performance benchmark before deploying deep learning models.

### 2. Fine-Tuned Transformer Model

| Parameter | Value |
|-----------|-------|
| **Model** | DistilBERT (uncased base) |
| **Architecture** | Transformer Encoder |
| **Training Environment** | Google Colab GPU |
| **Epochs** | 2â€“3 |
| **Batch Size** | 16 |
| **Accuracy** | ~94% |
| **F1-Score** | ~0.94 |

**Improvement:** DistilBERT significantly outperformed classical baseline while maintaining computational efficiency.

---

## ğŸ§ª Evaluation & Insights

âœ… **Confusion Matrix** â€“ Identified misclassification patterns  
âœ… **ROC-AUC Curve** â€“ Validated model discrimination ability  
âœ… **Class Distribution Check** â€“ Ensured balanced predictions  
âœ… **Error Analysis** â€“ Examined misclassified examples for robustness  

These evaluations ensured the model wasn't just accurate but **robust and interpretable**.

---

## ğŸš€ Deployment

The trained DistilBERT model is deployed using:

- **Frontend:** Gradio UI for user-friendly interaction
- **Hosting:** Hugging Face Spaces (serverless deployment)
- **Functionality:** Users enter any review text and receive instant sentiment prediction with confidence scores

### Example Usage

**Input:**
```
"The pasta tasted awful and was completely dry."
```

**Output:**
```
Sentiment: Negative
Confidence: 0.94
```

---

## ğŸ› ï¸ Tech Stack

| Component | Tools |
|-----------|-------|
| **Languages** | Python |
| **Deep Learning** | Transformers (Hugging Face), PyTorch |
| **Data Processing** | Scikit-learn, Pandas, NumPy |
| **Deployment** | Gradio, Hugging Face Spaces |
| **Environment** | Google Colab (GPU) |

---

## ğŸ“ Project Structure

```
amazon_food_review/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original dataset
â”‚   â””â”€â”€ processed/              # Cleaned & preprocessed data
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py         # Data loading utilities
â”‚   â”œâ”€â”€ preprocessing.py       # Text cleaning & tokenization
â”‚   â”œâ”€â”€ train_baseline.py      # Baseline model training
â”‚   â”œâ”€â”€ train_transformer.py   # DistilBERT fine-tuning
â”‚   â””â”€â”€ evaluate.py            # Model evaluation metrics
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ analysis.ipynb         # Exploratory data analysis
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ baseline_model.pkl
â”‚   â””â”€â”€ distilbert_model/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”§ Installation & Setup

### Prerequisites
- Python 3.8+
- pip or conda
- CUDA (optional, for GPU acceleration)

### Steps

1. **Clone the repository:**
   ```bash
   git clone https://github.com/YeswanthArasavalli/Amazon-Food-Review-Sentiment-Analysis.git
   cd Amazon-Food-Review-Sentiment-Analysis
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Download dataset:**
   - Download from [Kaggle](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews)
   - Place in `data/raw/`

4. **Run preprocessing:**
   ```bash
   python src/preprocessing.py
   ```

5. **Train models:**
   ```bash
   python src/train_baseline.py
   python src/train_transformer.py
   ```

6. **Evaluate results:**
   ```bash
   python src/evaluate.py
   ```

---

## ğŸ“ˆ Results Summary

| Model | Accuracy | F1-Score | Training Time |
|-------|----------|----------|----------------|
| Baseline (TF-IDF + LR) | 89% | 0.88 | ~5 min |
| DistilBERT | 94% | 0.94 | ~45 min (GPU) |

---

## ğŸ“ Key Learnings

- Deep learning models significantly outperform classical NLP approaches for sentiment analysis
- Transfer learning with pre-trained models (DistilBERT) provides strong performance with lower computational cost
- Comprehensive evaluation beyond accuracy (confusion matrices, ROC curves) is crucial for production models
- Cloud environments like Google Colab make advanced ML accessible without expensive hardware

---

## ğŸ“ Contact & Support

- **Author:** Yeswanth Arasavalli
- **GitHub:** [YeswanthArasavalli](https://github.com/YeswanthArasavalli)
- **Email:** [Your Email]
- **Project Issues:** [GitHub Issues](https://github.com/YeswanthArasavalli/Amazon-Food-Review-Sentiment-Analysis/issues)

---

## ğŸ“ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- Dataset: Kaggle Amazon Fine Food Reviews
- Model: Hugging Face Transformers
- Deployment: Gradio & Hugging Face Spaces
â”‚   â”œâ”€â”€ train_bert.py         
â”‚   â””â”€â”€ inference.py          
â”‚
â”œâ”€â”€ notebooks/                 
â”œâ”€â”€ models/                   
â”œâ”€â”€ app.py  (for deployment)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

â–¶ï¸ Run Locally

1. Clone repo

git clone https://github.com/YOUR_USERNAME/Amazon-Food-Review-Analysis.git
cd Amazon-Food-Review-Analysis


2. Install dependencies

pip install -r requirements.txt


3. Run preprocessing

python src/preprocessing.py


4. Train baseline

python src/train_baseline.py


5. Train BERT model (GPU recommended)

python src/train_bert.py


6. Run inference or Gradio app

python app.py

ğŸ“Œ** Key Outcomes**

Improved baseline accuracy (89% â†’ 94%) using fine-tuned DistilBERT

Successfully deployed an interactive NLP model for real-time inference

Built a scalable, reproducible ML pipeline following industry practices

ğŸš§** Future Enhancements**

Add neutral class to support 3-class sentiment classification

Experiment with RoBERTa / DeBERTa

Integrate MLflow experiment tracking

Deploy model as an API using FastAPI + Docker

â­ Author

ğŸ‘¤ Yeswanth Arasavalli
ğŸ“§ maneswararasavalli@gmail.com

ğŸ”— Hugging Face: https://huggingface.co/YeswanthArasavalli
